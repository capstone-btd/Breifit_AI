# NLLB νμΈνλ‹ λ²μ—­ ν”„λ΅μ νΈ

Facebookμ NLLB(No Language Left Behind) λ¨λΈμ„ νμΈνλ‹ν•μ—¬ ν•κµ­μ–΄-μμ–΄ λ²μ—­ μ„±λ¥μ„ ν–¥μƒμ‹ν‚¤λ” ν”„λ΅μ νΈμ…λ‹λ‹¤.

## π“ ν”„λ΅μ νΈ κµ¬μ΅°

```
β”β”€β”€ 01_nllb_import.py          # NLLB λ¨λΈ κΈ°λ³Έ μ‚¬μ©λ²•
β”β”€β”€ 02_data_preparation.py     # λ°μ΄ν„°μ…‹ μ¤€λΉ„ λ° μ „μ²λ¦¬
β”β”€β”€ 03_finetune_nllb.py       # νμΈνλ‹ μ‹¤ν–‰
β”β”€β”€ 04_use_finetuned_model.py # νμΈνλ‹λ λ¨λΈ μ‚¬μ©
β”β”€β”€ Dataset/                   # ν›λ ¨ λ°μ΄ν„° μ €μ¥ ν΄λ”
β”β”€β”€ finetuned_nllb/           # νμΈνλ‹λ λ¨λΈ μ €μ¥ ν΄λ”
β””β”€β”€ README.md                 # μ΄ νμΌ
```

## π€ λΉ λ¥Έ μ‹μ‘

### 1λ‹¨κ³„: ν•„μ”ν• ν¨ν‚¤μ§€ μ„¤μΉ

```bash
pip install torch transformers datasets tokenizers sentencepiece accelerate evaluate sacrebleu tqdm numpy pandas scikit-learn
```

### 2λ‹¨κ³„: κΈ°λ³Έ NLLB λ¨λΈ ν…μ¤νΈ

```bash
python 01_nllb_import.py
```

### 3λ‹¨κ³„: λ°μ΄ν„° μ¤€λΉ„

λ°μ΄ν„°λ¥Ό λ‹¤μ ν•μ‹μΌλ΅ μ¤€λΉ„ν•μ„Έμ”:

**CSV ν•μ‹:**
```csv
source_text,target_text
μ•λ…•ν•μ„Έμ”,Hello
κ°μ‚¬ν•©λ‹λ‹¤,Thank you
```

**JSON ν•μ‹:**
```json
[
  {"source": "μ•λ…•ν•μ„Έμ”", "target": "Hello"},
  {"source": "κ°μ‚¬ν•©λ‹λ‹¤", "target": "Thank you"}
]
```

### 4λ‹¨κ³„: νμΈνλ‹ μ‹¤ν–‰

```bash
python 03_finetune_nllb.py
```

### 5λ‹¨κ³„: νμΈνλ‹λ λ¨λΈ μ‚¬μ©

```bash
python 04_use_finetuned_model.py
```

## π› οΈ μƒμ„Έ μ‚¬μ©λ²•

### 1. κΈ°λ³Έ NLLB λ¨λΈ μ‚¬μ©

```python
from nllb_import import NLLBModel

# λ¨λΈ μ΄κΈ°ν™”
nllb = NLLBModel("facebook/nllb-200-distilled-600M")

# λ²μ—­ μ‹¤ν–‰
result = nllb.translate("μ•λ…•ν•μ„Έμ”", "kor_Hang", "eng_Latn")
print(result)  # Hello
```

### 2. λ°μ΄ν„°μ…‹ μ¤€λΉ„

```python
from data_preparation import load_data_from_csv, create_sample_data

# CSVμ—μ„ λ°μ΄ν„° λ΅λ“
source_texts, target_texts = load_data_from_csv("your_data.csv")

# λλ” μƒν” λ°μ΄ν„° μ‚¬μ©
source_texts, target_texts = create_sample_data()
```

### 3. νμΈνλ‹

```python
from finetune_nllb import NLLBFineTuner

# νμΈνλ„ μ΄κΈ°ν™”
fine_tuner = NLLBFineTuner()

# ν›λ ¨ μ‹¤ν–‰
fine_tuner.train(
    source_texts=source_texts,
    target_texts=target_texts,
    epochs=10,
    learning_rate=5e-5,
    batch_size=4
)
```

### 4. νμΈνλ‹λ λ¨λΈ μ‚¬μ©

```python
from use_finetuned_model import FineTunedNLLBTranslator

# λ²μ—­κΈ° μ΄κΈ°ν™”
translator = FineTunedNLLBTranslator("./finetuned_nllb")

# λ²μ—­ μ‹¤ν–‰
result = translator.translate("μ•λ…•ν•μ„Έμ”")
print(result)
```

## π― μ§€μ›ν•λ” μ–Έμ–΄

| μ–Έμ–΄ | μ½”λ“ |
|------|------|
| ν•κµ­μ–΄ | kor_Hang |
| μμ–΄ | eng_Latn |
| μΌλ³Έμ–΄ | jpn_Jpan |
| μ¤‘κµ­μ–΄(κ°„μ²΄) | zho_Hans |
| μ¤‘κµ­μ–΄(λ²μ²΄) | zho_Hant |
| μ¤νμΈμ–΄ | spa_Latn |
| ν”„λ‘μ¤μ–΄ | fra_Latn |
| λ…μΌμ–΄ | deu_Latn |
| λ¬μ‹μ•„μ–΄ | rus_Cyrl |
| μ•„λμ–΄ | arb_Arab |

## β™οΈ νμΈνλ‹ νλΌλ―Έν„° μ΅°μ •

### GPU λ©”λ¨λ¦¬μ— λ”°λ¥Έ λ°°μΉ ν¬κΈ° μ΅°μ •

- **4GB GPU**: batch_size=1
- **8GB GPU**: batch_size=2-4
- **16GB GPU**: batch_size=4-8
- **24GB+ GPU**: batch_size=8+

### ν•™μµλ¥  μ΅°μ •

- **κΈ°λ³Έκ°’**: 5e-5
- **λ” λ³΄μμ **: 1e-5
- **λ” κ³µκ²©μ **: 1e-4

### μ—ν¬ν¬ μ

- **μ†κ·λ¨ λ°μ΄ν„°**: 10-20 μ—ν¬ν¬
- **λ€κ·λ¨ λ°μ΄ν„°**: 3-5 μ—ν¬ν¬

## π“ μ„±λ¥ λ¨λ‹ν„°λ§

ν›λ ¨ μ¤‘ λ‹¤μ μ§€ν‘λ“¤μ„ λ¨λ‹ν„°λ§ν•μ„Έμ”:

- **ν›λ ¨ μ†μ‹¤ (Training Loss)**: κ°μ†ν•΄μ•Ό ν•¨
- **κ²€μ¦ μ†μ‹¤ (Validation Loss)**: κ°μ† ν›„ μ•μ •ν™”
- **κ³Όμ ν•© κ°μ§€**: κ²€μ¦ μ†μ‹¤μ΄ μ¦κ°€ν•κΈ° μ‹μ‘ν•λ©΄ μ΅°κΈ° μΆ…λ£

## π”§ λ¬Έμ  ν•΄κ²°

### 1. CUDA λ©”λ¨λ¦¬ λ¶€μ΅±

```python
# λ°°μΉ ν¬κΈ° μ¤„μ΄κΈ°
batch_size = 1

# κ·Έλλ””μ–ΈνΈ λ„μ  μ‚¬μ©
accumulation_steps = 4
```

### 2. ν›λ ¨μ΄ λλ¦° κ²½μ°

```python
# λ” μ‘μ€ λ¨λΈ μ‚¬μ©
model_name = "facebook/nllb-200-distilled-600M"  # λ€μ‹  600M λ¨λΈ μ‚¬μ©

# νΌν•© μ •λ°€λ„ ν›λ ¨
from torch.cuda.amp import autocast, GradScaler
```

### 3. λ²μ—­ ν’μ§μ΄ λ‚®μ€ κ²½μ°

- λ” λ§μ€ ν›λ ¨ λ°μ΄ν„° μμ§‘
- μ—ν¬ν¬ μ μ¦κ°€
- ν•™μµλ¥  μ΅°μ •
- λ°μ΄ν„° ν’μ§ κ²€ν† 

## π“ μ£Όμμ‚¬ν•­

1. **λ°μ΄ν„° ν’μ§**: κ³ ν’μ§μ λ³‘λ ¬ λ°μ΄ν„°κ°€ ν•„μ
2. **GPU λ©”λ¨λ¦¬**: μµμ† 4GB GPU κ¶μ¥
3. **ν›λ ¨ μ‹κ°„**: λ°μ΄ν„° ν¬κΈ°μ— λ”°λΌ λ‡ μ‹κ°„μ—μ„ λ©°μΉ  μ†μ”
4. **λ¨λΈ ν¬κΈ°**: νμΈνλ‹λ λ¨λΈμ€ 1-3GB ν¬κΈ°

## π¤ κΈ°μ—¬ λ°©λ²•

1. μ΄μ λ“±λ΅
2. ν¬ν¬ ν›„ λΈλμΉ μƒμ„±
3. λ³€κ²½μ‚¬ν•­ μ»¤λ°‹
4. ν’€ λ¦¬ν€μ¤νΈ μƒμ„±

## οΏ½οΏ½ λΌμ΄μ„ μ¤

MIT License
