import asyncio
import yaml
import os
import sys
from datetime import datetime
import argparse
import re
import logging

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

# ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
MODELS_ROOT = os.path.join(os.path.dirname(PROJECT_ROOT), 'models')
if MODELS_ROOT not in sys.path:
    sys.path.append(MODELS_ROOT)

from src.collection import COLLECTOR_CLASSES
from src.utils.file_helper import save_json_async, get_output_path, slugify
from src.utils.logger import setup_logger

# ë²ˆì—­ê¸° import (ì„ íƒì )
try:
    from translation.nllb_translator import NLLBTranslator
    TRANSLATION_AVAILABLE = True
except ImportError as e:
    print(f"ë²ˆì—­ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("ë²ˆì—­ ê¸°ëŠ¥ ì—†ì´ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    TRANSLATION_AVAILABLE = False

CONFIG_FILE_PATH = os.path.join(PROJECT_ROOT, 'configs', 'news_sites.yaml')
RAW_DATA_BASE_DIR = os.path.join(PROJECT_ROOT, 'data', 'raw')

# ê¸€ë¡œë²Œ ë²ˆì—­ê¸° ì¸ìŠ¤í„´ìŠ¤
translator = None

def initialize_translator():
    """
    ë²ˆì—­ê¸° ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰)
    """
    global translator
    if TRANSLATION_AVAILABLE and translator is None:
        try:
            print("ë²ˆì—­ê¸° ì´ˆê¸°í™” ì¤‘... (NHNDQ/nllb-finetuned-en2ko)")
            translator = NLLBTranslator()
            model_info = translator.get_model_info()
            print(f"ë²ˆì—­ê¸° ë¡œë“œ ì™„ë£Œ: {model_info['model_name']}")
            print(f"ë²ˆì—­ ë°©í–¥: {model_info['source_language']} â†’ {model_info['target_language']}")
            return True
        except Exception as e:
            print(f"ë²ˆì—­ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            translator = None
            return False
    return TRANSLATION_AVAILABLE

def preprocess_text_simple(text: str) -> str:
    """
    ê¸°ëŠ¥: ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ê³µë°±, íŠ¹ìˆ˜ë¬¸ì, ì´ë©”ì¼, URL, ì €ì‘ê¶Œ ë¬¸êµ¬ ë“±ì„ ì œê±°í•œë‹¤.
    input: ì›ë³¸ í…ìŠ¤íŠ¸ (str)
    output: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ (str)
    """
    if not text or not isinstance(text, str):
        return ""
    text = re.sub(r'\s+', ' ', text).strip()
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'\(.*?\)', '', text)
    text = re.sub(r'\S+@\S+', '', text)
    text = re.sub(r'https?://\S+', '', text)
    text = re.sub(r'[\\/]', '', text)
    text = re.sub(r'[^A-Za-z0-9ê°€-í£\s.,\'"%Â·-]', '', text) 
    copyright_pattern = r'(ì €ì‘ê¶Œì|copyright|â“’|Â©)\s?\(?c\)?\s?\w*|ë¬´ë‹¨\s?(ì „ì¬|ë°°í¬|ì¬ë°°í¬)\s?ê¸ˆì§€|AI\s?í•™ìŠµ\s?ë°\s?í™œìš©\s?ê¸ˆì§€|All\s?rights\s?reserved'
    text = re.sub(copyright_pattern, '', text, flags=re.IGNORECASE)
    text = re.sub(r'[\w\.-]+@[\w\.-]+', '', text)
    text = re.sub(r'\d{4}[/\.]\d{2}[/\.]\d{2}\s\d{2}:\d{2}\sì†¡ê³ ', '', text)
    return text.strip()

def load_config(config_path: str) -> dict:
    """
    ê¸°ëŠ¥: YAML ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•œë‹¤.
    input: ì„¤ì • íŒŒì¼ ê²½ë¡œ (str)
    output: ì„¤ì • ë‚´ìš©ì´ ë‹´ê¸´ ë”•ì…”ë„ˆë¦¬ (dict)
    """
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
        return config
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: ì„¤ì • íŒŒì¼({config_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except yaml.YAMLError as e:
        print(f"ì˜¤ë¥˜: ì„¤ì • íŒŒì¼({config_path})ì„ íŒŒì‹±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"ì˜¤ë¥˜: ì„¤ì • íŒŒì¼ ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

async def run_collection_for_site(site_name: str, site_config: dict, collection_time_str: str):
    """
    ê¸°ëŠ¥: ë‹¨ì¼ ì‚¬ì´íŠ¸ì— ëŒ€í•´ ê¸°ì‚¬ ìˆ˜ì§‘, ì „ì²˜ë¦¬ ë° ì €ì¥ì„ ìˆ˜í–‰í•œë‹¤.
    input: ì‚¬ì´íŠ¸ ì´ë¦„(site_name), ì‚¬ì´íŠ¸ ì„¤ì •(site_config), ìˆ˜ì§‘ ì‹œê°„(collection_time_str)
    output: ì—†ìŒ
    """
    if site_name not in COLLECTOR_CLASSES:
        print(f"ê²½ê³ : '{site_name}'ì— ëŒ€í•œ ì»¬ë ‰í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    collector_class = COLLECTOR_CLASSES.get(site_name.lower())
    if not collector_class:
        print(f"Error: Collector for site '{site_name}' not found.")
        return

    collector = collector_class()
    
    print(f"\n--- ì‚¬ì´íŠ¸ ì‹œì‘: {site_name.upper()} ---")

    categories_config = site_config.get('categories')
    if not categories_config or not isinstance(categories_config, dict):
        print(f"ê²½ê³ : '{site_name}'ì— ëŒ€í•œ ì¹´í…Œê³ ë¦¬ ì„¤ì •ì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    total_articles_collected_for_site = 0

    for category_display_name, category_path_segment in categories_config.items():
        articles_data = []
        
        if isinstance(category_path_segment, list):
            print(f"ì¹´í…Œê³ ë¦¬ '{category_display_name.upper()}' (ë‹¤ì¤‘ ê²½ë¡œ) ìˆ˜ì§‘ ì‹œì‘: {category_path_segment}...")
            for path_segment in category_path_segment:
                print(f"  ê²½ë¡œ '{path_segment}' ì—ì„œ ìˆ˜ì§‘ ì¤‘...")
                articles_from_path = await collector.collect_by_category(category_display_name, path_segment)
                if articles_from_path:
                    articles_data.extend(articles_from_path)
        elif isinstance(category_path_segment, str):
            print(f"ì¹´í…Œê³ ë¦¬ '{category_display_name.upper()}' ìˆ˜ì§‘ ì‹œì‘ ({category_path_segment})...")
            articles_from_path = await collector.collect_by_category(category_display_name, category_path_segment)
            if articles_from_path:
                articles_data.extend(articles_from_path)
        else:
            print(f"ê²½ê³ : ì¹´í…Œê³ ë¦¬ '{category_display_name.upper()}'ì˜ ê²½ë¡œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤(ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨): {category_path_segment}. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        if not articles_data:
            print(f"ì¹´í…Œê³ ë¦¬ '{category_display_name.upper()}' ({site_name})ì—ì„œ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        print(f"ì¹´í…Œê³ ë¦¬ '{category_display_name.upper()}' ({site_name})ì—ì„œ {len(articles_data)}ê°œì˜ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ. ì „ì²˜ë¦¬ ë° íŒŒì¼ ì €ì¥ ì‹œì‘...")
        
        saved_count_for_category = 0
        save_tasks = []
        for article in articles_data:
            if not article or not article.get('title') or not article.get('url'):
                print(f"ê²½ê³ : í•„ìˆ˜ ì •ë³´(ì œëª© ë˜ëŠ” URL)ê°€ ì—†ëŠ” ê¸°ì‚¬ê°€ ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤: {article}")
                continue

            original_article_text = article.get('article_text')
            original_title = article.get('title')
            
            # ì›ë³¸ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            if original_article_text:
                processed_text = preprocess_text_simple(original_article_text)
                article['article_text'] = processed_text
                print(f"  - '{original_title[:30]}' ê¸°ì‚¬ ì „ì²˜ë¦¬ ì™„ë£Œ.")
            else:
                article['article_text'] = ""
            
            # ì–¸ì–´ ê°ì§€ ë° ë²ˆì—­ (ë²ˆì—­ê¸°ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            if translator and article.get('article_text'):
                try:
                    # ë³¸ë¬¸ì´ ì˜ì–´ì¸ì§€ í™•ì¸
                    if translator.is_english_text(article['article_text']):
                        print(f"    ì˜ì–´ í…ìŠ¤íŠ¸ ê°ì§€ - í•œêµ­ì–´ë¡œ ë²ˆì—­ ì‹œì‘")
                        
                        content_to_translate = article['article_text']
                        
                        print(f"    [ê²€ì¦] ë²ˆì—­ê¸°ë¡œ ì „ë‹¬ë˜ëŠ” ì›ë¬¸ ê¸¸ì´: {len(content_to_translate)}ì")
                        print(f"    [ê²€ì¦] ì›ë¬¸ ì•ë¶€ë¶„: {content_to_translate[:150]}...")
                        
                        # ì˜ì–´ â†’ í•œêµ­ì–´ ë²ˆì—­
                        translated_content = translator.translate(content_to_translate)
                        
                        # ì›ë³¸ article_textë¥¼ ë²ˆì—­ëœ í•œêµ­ì–´ë¡œ êµì²´
                        article['article_text'] = translated_content
                        
                        print(f"    ë²ˆì—­ ì™„ë£Œ ({len(content_to_translate)}ì â†’ {len(translated_content)}ì)")
                        print(f"    ë²ˆì—­ ê²°ê³¼: {translated_content[:50]}...")
                    else:
                        print(f"    í•œêµ­ì–´ í…ìŠ¤íŠ¸ - ë²ˆì—­ ë¶ˆí•„ìš”")
                    
                except Exception as e:
                    print(f"    ë²ˆì—­ ì‹¤íŒ¨: {e}")

            article_title_slug = slugify(article['title'])
            if not article_title_slug:
                url_path_parts = [part for part in article['url'].split('/') if part]
                if url_path_parts:
                    article_title_slug = slugify(url_path_parts[-1])
                    if not article_title_slug and len(url_path_parts) > 1:
                         article_title_slug = slugify(url_path_parts[-2])
            if not article_title_slug:
                article_title_slug = f"untitled-article-{datetime.now().strftime('%Y%m%d%H%M%S%f')}"

            output_filename = f"{article_title_slug}.json"
            file_path = get_output_path(
                base_dir=RAW_DATA_BASE_DIR,
                site_name=site_name,
                category_name=category_display_name,
                filename=output_filename,
                collection_time_str=collection_time_str
            )
            
            save_tasks.append(save_json_async(article, file_path))
            saved_count_for_category +=1
        
        await asyncio.gather(*save_tasks)
        print(f"ì¹´í…Œê³ ë¦¬ '{category_display_name.upper()}' ({site_name}): {saved_count_for_category}ê°œ ê¸°ì‚¬ ì €ì¥ ì™„ë£Œ.")
        total_articles_collected_for_site += saved_count_for_category

    print(f"--- ì‚¬ì´íŠ¸ {site_name.upper()} ì¢…ë£Œ: ì´ {total_articles_collected_for_site}ê°œ ê¸°ì‚¬ ì²˜ë¦¬ ---")

async def main():
    """
    ê¸°ëŠ¥: ì„¤ì • íŒŒì¼ì„ ì½ì–´ ê¸°ì‚¬ ìˆ˜ì§‘ì„ ìœ„í•œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ê´€ì¥í•˜ê³  ì‹¤í–‰í•œë‹¤.
    input: ì—†ìŒ
    output: ì—†ìŒ
    """
    # ë²ˆì—­ê¸° ì´ˆê¸°í™”
    translation_enabled = initialize_translator()
    if translation_enabled:
        print("âœ… ë²ˆì—­ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")3


    else:
        print("â„¹ï¸  ë²ˆì—­ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    config = load_config(CONFIG_FILE_PATH)
    sites_to_crawl = config.get('sites')

    if not sites_to_crawl or not isinstance(sites_to_crawl, dict):
        print("ì˜¤ë¥˜: ì„¤ì • íŒŒì¼ì—ì„œ 'sites' ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    collection_time_str = datetime.now().strftime('%Y%m%d_%H%M%S')
    target_sites_to_run = sites_to_crawl

    tasks = []
    for site_name, site_config_data in target_sites_to_run.items():
        if not isinstance(site_config_data, dict):
            print(f"ê²½ê³ : '{site_name}' ì‚¬ì´íŠ¸ ì„¤ì •ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        tasks.append(run_collection_for_site(site_name, site_config_data, collection_time_str))
    
    await asyncio.gather(*tasks)

    print("\nëª¨ë“  ì‚¬ì´íŠ¸ ìˆ˜ì§‘ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    if translation_enabled:
        print("ğŸ“Š ë²ˆì—­ í†µê³„:")
        print(f"   - ë²ˆì—­ê¸° ëª¨ë¸: {translator.model_name}")
        print(f"   - ë””ë°”ì´ìŠ¤: {translator.device}")
        print("   - ì˜ì–´ ê¸°ì‚¬ëŠ” í•œêµ­ì–´ë¡œ ë²ˆì—­ë˜ì–´ article_textì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == '__main__':
    asyncio.run(main())